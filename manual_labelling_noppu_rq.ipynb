{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruinoah5/AI6102-ML-Metho/blob/main/manual_labelling_noppu_rq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgrAvZR_B6SV",
        "outputId": "4d2d1d76-bda3-4264-9fd1-1c0bcfad0b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['MyDrive', '.shortcut-targets-by-id', '.Trash-0', '.Encrypted']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os # Import os module to use os.listdir\n",
        "\n",
        "path = '/content/drive'\n",
        "drive.mount(path) # Mount the drive first\n",
        "print(os.listdir(path)) # Then list its contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO-5n2qoDD5I",
        "outputId": "732ccfc1-417d-4bc0-a998-93f0c6128916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos found:  100\n",
            "['01.mp4', '02.mp4', '03.mp4', '04.mp4', '05.mp4', '06.mp4', '07.mp4', '08.mp4', '09.mp4', '10.mp4', '11.mp4', '12.mp4', '13.mp4', '14.mp4', '15.mp4', '16.mp4', '17.mp4', '18.mp4', '19.mp4', '20.mp4', '21.mp4', '22.mp4', '23.mp4', '24.mp4', '25.mp4', '26.mp4', '27.mp4', '28.mp4', '29.mp4', '30.mp4', '31.mp4', '32.mp4', '33.mp4', '34.mp4', '35.mp4', '36.mp4', '37.mp4', '38.mp4', '39.mp4', '40.mp4', '41.mp4', '42.mp4', '43.mp4', '44.mp4', '45.mp4', '46.mp4', '47.mp4', '48.mp4', '49.mp4', '50.mp4', '51.mp4', '52.mp4', '53.mp4', '54.mp4', '55.mp4', '56.mp4', '57.mp4', '58.mp4', '59.mp4', '60.mp4', '61.mp4', '62.mp4', '63.mp4', '64.mp4', '65.mp4', '66.mp4', '67.mp4', '68.mp4', '69.mp4', '70.mp4', '71.mp4', '72.mp4', '73.mp4', '74.mp4', '75.mp4', '76.mp4', '77.mp4', '78.mp4', '79.mp4', '80.mp4', '81.mp4', '82.mp4', '83.mp4', '84.mp4', '85.mp4', '86.mp4', '87.mp4', '88.mp4', '89.mp4', '90.mp4', '91.mp4', '92.mp4', '93.mp4', '94.mp4', '95.mp4', '96.mp4', '97.mp4', '98.mp4', '99.mp4']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#video_folder = path + '/MyDrive/ColabNotebooks/mixed_group_21'\n",
        "video_folder = path + '/MyDrive/AI6102 Machine Learning: Methodologies & Applications/mixed_group_21'\n",
        "videos = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "videos.sort()\n",
        "\n",
        "print('Total videos found: ', len(videos))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def display_video_autoplay(path, width=500, height=405, loop=True, controls=True):\n",
        "    with open(path, \"rb\") as f:\n",
        "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=\"{width}\" height=\"{height}\"\n",
        "           {\"controls\" if controls else \"\"} autoplay muted playsinline {\"loop\" if loop else \"\"}\n",
        "           style=\"display:block; max-width:100%; border:1px solid #ddd;\">\n",
        "      <source src=\"data:video/mp4;base64,{b64}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\"))\n"
      ],
      "metadata": {
        "id": "3QisjAQWglCX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, random\n",
        "from IPython.display import clear_output, display as ipy_display\n",
        "\n",
        "def ask_questions_one_by_one(video_name, video_path, section_name, questions):\n",
        "    n = len(questions)\n",
        "    #questions\n",
        "    # Initialize the answers_list with '0' for no violations for all questions in this section\n",
        "    # This correctly modifies the list passed by reference from ground_truth\n",
        "    answers_list = [0, 0, 0, 0, 0]\n",
        "    reasons_str = \"\" # Initialize reasons_str here to ensure it's always defined\n",
        "\n",
        "    scaleFactor = 1\n",
        "    display_video_autoplay(video_path, width=scaleFactor*2688, height=scaleFactor*600, loop=True)\n",
        "    print(f'Consider [{section_name}] of [{video_name}]\\n')\n",
        "    print('Questions for this section:\\n')\n",
        "    for i, q in enumerate(questions):\n",
        "        print(f'{q}')\n",
        "    time.sleep(0.2)\n",
        "\n",
        "    while True:\n",
        "        # Prompt user to input violated question numbers\n",
        "        user_input = input(f\"\\nKey in ONLY the question numbers that the generated video has violated (e.g., '1, 3')\\n\")\n",
        "\n",
        "        try:\n",
        "            if user_input.strip() == '0':\n",
        "                print(str(answers_list))\n",
        "                break\n",
        "\n",
        "            # Parse the input string into a list of integers\n",
        "            reasons_str = input(f\"\\nKey in the reasons why they are being violated?\\n\") # This local variable will be returned\n",
        "            violated_nums_str = [x.strip() for x in user_input.split(',')]\n",
        "            violated_nums = []\n",
        "\n",
        "            for s in violated_nums_str:\n",
        "                num = int(s)\n",
        "                if not (1 <= num <= n):\n",
        "                    raise ValueError(f\"Question number '{num}' is out of range (1-{n}).\")\n",
        "                if num in violated_nums: # Check for duplicates\n",
        "                    raise ValueError(f\"Question number '{num}' entered multiple times.\")\n",
        "                violated_nums.append(num)\n",
        "\n",
        "            # Mark the violated questions in the answers_list\n",
        "            for q_num in violated_nums:\n",
        "                answers_list[q_num - 1] = 1 # Set to 1 for violated (using 0-based indexing)\n",
        "            print(str(answers_list))\n",
        "            input('Review, then press Enter to continue: ')\n",
        "            break\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input: {e}. Please try again.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}. Please try again.\")\n",
        "\n",
        "\n",
        "    clear_output(wait=True) # Clear output for the next section\n",
        "    return answers_list, reasons_str # Return both the updated answers_list and reasons_str\n"
      ],
      "metadata": {
        "id": "admsY90Iqz0D"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = {\n",
        "    \"Questions\": {\n",
        "        \"semantic_correctness\": semantic_questions,\n",
        "        \"physical_consistency\": physical_questions,\n",
        "        \"decision_rationality\": decision_questions\n",
        "    },\n",
        "    \"Answers\": {\n",
        "        \"semantic_correctness\": [],\n",
        "        \"physical_consistency\": [],\n",
        "        \"decision_rationality\": []\n",
        "    },\n",
        "    \"Reasons\": {\n",
        "        \"semantic_correctness\": \"\",\n",
        "        \"physical_consistency\": \"\",\n",
        "        \"decision_rationality\": \"\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for video in videos[33:65]: # Iterate over only the first video\n",
        "    video_path = os.path.join(video_folder, video)\n",
        "\n",
        "    # ground_truth[\"Answers\"][video] = {\n",
        "    #     \"semantic_correctness\": [],\n",
        "    #     \"physical_consistency\": [],\n",
        "    #     \"decision_rationality\": []\n",
        "    # }\n",
        "\n",
        "    # ground_truth[\"Reasons\"][video] = {\n",
        "    #     \"semantic_correctness\": \"\",\n",
        "    #     \"physical_consistency\": \"\",\n",
        "    #     \"decision_rationality\": \"\"\n",
        "    # }\n",
        "\n",
        "    ground_truth[\"Answers\"][video][\"semantic_correctness\"], ground_truth[\"Reasons\"][video][\"semantic_correctness\"] = ask_questions_one_by_one(\n",
        "        video, video_path,\n",
        "        \"Semantic Correctness\",\n",
        "        semantic_questions\n",
        "    )\n",
        "\n",
        "    ground_truth[\"Answers\"][video][\"physical_consistency\"], ground_truth[\"Reasons\"][video][\"physical_consistency\"] = ask_questions_one_by_one(\n",
        "        video, video_path,\n",
        "        \"Physical Consistency\",\n",
        "        physical_questions\n",
        "    )\n",
        "\n",
        "    ground_truth[\"Answers\"][video][\"decision_rationality\"], ground_truth[\"Reasons\"][video][\"decision_rationality\"] = ask_questions_one_by_one(\n",
        "        video, video_path,\n",
        "        \"Decision Rationality\",\n",
        "        decision_questions\n",
        "    )\n",
        "\n",
        "clear_output(wait=True)\n",
        "print(\"✅ Done! ground_truth is ready.\")\n",
        "\n",
        "ground_truth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vWzSHmE1qzxu",
        "outputId": "45283774-abe2-448a-ee29-e7022b873569"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'33.mp4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1667443202.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     ground_truth[\"Answers\"][video][\"semantic_correctness\"], ground_truth[\"Reasons\"][video][\"semantic_correctness\"] = ask_questions_one_by_one(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"Semantic Correctness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '33.mp4'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed61286a"
      },
      "source": [
        "# Method 1: Initialize an empty outer dictionary and then add inner dictionaries\n",
        "outer_dict = {}\n",
        "outer_dict['key1'] = {'inner_key_a': 1, 'inner_key_b': 2}\n",
        "outer_dict['key2'] = {'inner_key_c': 3, 'inner_key_d': 4}\n",
        "display(outer_dict)\n",
        "\n",
        "# Method 2: Initialize directly with nested dictionaries\n",
        "initial_data = {\n",
        "    'video_01.mp4': {\n",
        "        'semantic_correctness': [],\n",
        "        'physical_consistency': [],\n",
        "        'decision_rationality': []\n",
        "    },\n",
        "    'video_02.mp4': {\n",
        "        'semantic_correctness': [],\n",
        "        'physical_consistency': [],\n",
        "        'decision_rationality': []\n",
        "    }\n",
        "}\n",
        "display(initial_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "semantic_questions_str = '''\n",
        "1. Is any vehicle missing, duplicated, or clearly misrepresented?\n",
        "2. Is any pedestrian missing, duplicated, or incorrectly placed?\n",
        "3. Are traffic light states incorrect or inconsistent with the scene?\n",
        "4. Are lane markings missing, distorted, or suddenly changed?\n",
        "5. Are road signs incorrect, missing, or inconsistent with context?\n",
        "'''\n",
        "semantic_questions = [x for x in semantic_questions_str.split('\\n') if x != '']\n",
        "semantic_questions\n",
        "\n",
        "\n",
        "physical_questions_str = '''\n",
        "1. Does any object violate physical consistency (e.g., teleport, overlap unnaturally, geometry is off, wheels floating)?\n",
        "2. Is there any temporal inconsistency across consecutive frames (The individual frames might look physically correct — but the transition between frames is impossible)?\n",
        "3. -\n",
        "4. -\n",
        "5. -\n",
        "'''\n",
        "physical_questions = [x for x in physical_questions_str.split('\\n') if x != '']\n",
        "physical_questions\n",
        "\n",
        "decision_questions_str = '''\n",
        "1. Does the vehicle fail to stop at a red light/ go at a green light?\\n\n",
        "2. Does the vehicle fail to yield to pedestrians or other vehicles?\\n\n",
        "3. Is obstacle avoidance handled improperly or too late?\\n\n",
        "4. Does the vehicle perform a dangerous or unreasonable maneuver?\\n\\n\n",
        "5. -\n",
        "'''\n",
        "decision_questions = [x for x in decision_questions_str.split('\\n') if x != '']\n",
        "decision_questions"
      ],
      "metadata": {
        "id": "rIshJex4ZcNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f381d9df-e30f-448c-ce30-cfd2fb87d6d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. Does the vehicle fail to stop at a red light/ go at a green light?',\n",
              " '2. Does the vehicle fail to yield to pedestrians or other vehicles?',\n",
              " '3. Is obstacle avoidance handled improperly or too late?',\n",
              " '4. Does the vehicle perform a dangerous or unreasonable maneuver?',\n",
              " '5. -']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-Kf_uEsZJ2Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542f341e-33b1-474b-f1c6-cea2f6542fb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Questions': {'semantic_correctness': ['1. Is any vehicle missing, duplicated, or clearly misrepresented?',\n",
              "   '2. Is any pedestrian missing, duplicated, or incorrectly placed?',\n",
              "   '3. Are traffic light states incorrect or inconsistent with the scene?',\n",
              "   '4. Are lane markings missing, distorted, or suddenly changed?',\n",
              "   '5. Are road signs incorrect, missing, or inconsistent with context?'],\n",
              "  'physical_consistency': ['1. Does any object violate physical consistency (e.g., teleport, overlap unnaturally, geometry is off, wheels floating)?',\n",
              "   '2. Is there any temporal inconsistency across consecutive frames (The individual frames might look physically correct — but the transition between frames is impossible)?',\n",
              "   '3. -',\n",
              "   '4. -',\n",
              "   '5. -'],\n",
              "  'decision_rationality': ['1. Does the vehicle fail to stop at a red light/ go at a green light?',\n",
              "   '2. Does the vehicle fail to yield to pedestrians or other vehicles?',\n",
              "   '3. Is obstacle avoidance handled improperly or too late?',\n",
              "   '4. Does the vehicle perform a dangerous or unreasonable maneuver?',\n",
              "   '5. -']},\n",
              " 'Answers': {'33.mp4': {'semantic_correctness': [1, 0, 0, 0, 0],\n",
              "   'physical_consistency': [0, 1, 0, 0, 0],\n",
              "   'decision_rationality': [1, 0, 0, 0, 0]},\n",
              "  '34.mp4': {'semantic_correctness': [],\n",
              "   'physical_consistency': [],\n",
              "   'decision_rationality': []}},\n",
              " 'Reasons': {'33.mp4': {'semantic_correctness': 'bad',\n",
              "   'physical_consistency': 'worse',\n",
              "   'decision_rationality': 'werid'},\n",
              "  '34.mp4': {'semantic_correctness': '',\n",
              "   'physical_consistency': '',\n",
              "   'decision_rationality': ''}}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import json\n",
        "labeler = 'ruiqi_test'\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/AI6102 Machine Learning: Methodologies & Applications/RuiQi/ColabNotebooks/'\n",
        "with open(f\"{folder_path}ground_truth_{labeler}.json\", \"w\") as f:\n",
        "    json.dump(ground_truth, f, indent=4)\n",
        "\n",
        "with open(f\"{folder_path}ground_truth_{labeler}.json\", \"r\") as f:\n",
        "    temp = json.load(f)\n",
        "\n",
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# semantic_questions_str = '''\n",
        "# 1. Does any vehicle appear or disappear abruptly without occlusion?\\n\n",
        "# 2. Does any pedestrian appear or disappear abruptly without occlusion?\\n\n",
        "# 3. Is any traffic light state inconsistent across nearby frames?\\n\n",
        "# 4. Are lane markings inconsistent or suddenly changing shape/type?\\n\n",
        "# 5. Is any object clearly misclassified (e.g., pedestrian as vehicle)?\\n\n",
        "# 6. Do object counts change suddenly without scene justification?\\n\n",
        "# 7. Do road signs change identity between adjacent frames?\\n\n",
        "# 8. Are object positions inconsistent with camera motion?\\n\n",
        "# 9. Is any major road element missing when it should be visible?\\n\n",
        "# 10. Are object sizes clearly unrealistic relative to scene scale?\\n\n",
        "# '''\n",
        "\n",
        "\n",
        "# physical_questions_str = '''\n",
        "# 1. Does any object teleport between consecutive frames?\\n\n",
        "# 2. Does any object move with physically impossible speed?\\n\n",
        "# 3. Are trajectories discontinuous without collision/occlusion?\\n\n",
        "# 4. Do objects overlap in space unrealistically?\\n\n",
        "# 5. Does any collision occur without spatial contact?\\n\n",
        "# 6. Do objects pass through solid obstacles?\\n\n",
        "# 7. Are shadows/reflections inconsistent with object motion?\\n\n",
        "# 8. Does ego vehicle motion violate smooth acceleration patterns?\\n\n",
        "# 9. Are turns or rotations physically implausible?\\n\n",
        "# 10.Does depth ordering flip incorrectly between frames?\\n\n",
        "# '''\n",
        "\n",
        "\n",
        "# decision_questions_str = '''\n",
        "# 1.Did the ego vehicle run a red light?\\n\n",
        "# 2.Did the ego vehicle ignore a visible stop sign?\\n\n",
        "# 3.Did the ego vehicle fail to yield to pedestrians?\\n\n",
        "# 4.Did the ego vehicle fail to brake for a clear obstacle?\\n\n",
        "# 5.Did the ego vehicle make an unsafe lane change?\\n\n",
        "# 6.Did the ego vehicle follow too closely at speed?\\n\n",
        "# 7.Did the ego vehicle turn across oncoming traffic unsafely?\\n\n",
        "# 8.Did the ego vehicle accelerate toward a visible hazard?\\n\n",
        "# 9.Did the ego vehicle ignore right-of-way rules?\\n\n",
        "# 10. Did the ego vehicle create a near-collision risk by its action?\\n\n",
        "# '''\n"
      ],
      "metadata": {
        "id": "1-GbyZ1RLNhR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0uCTi06LQep"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}